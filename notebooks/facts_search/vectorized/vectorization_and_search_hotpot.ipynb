{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import faiss\n",
    "import json\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.cuda\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load hotpot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "facts_path = \"corpus.jsonl\"\n",
    "with open(facts_path) as f:\n",
    "    fact_sets = [json.loads(line) for line in f.readlines()]\n",
    "facts = [fact_set[\"text\"] for fact_set in fact_sets]\n",
    "\n",
    "facts_path = \"queries.jsonl\"\n",
    "with open(facts_path) as f:\n",
    "    questions_sets = [json.loads(line) for line in f.readlines()]\n",
    "questions = [questions_set[\"text\"] for questions_set in questions_sets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5233329"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(facts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8237 0\n",
      "1377 0\n"
     ]
    }
   ],
   "source": [
    "# check min and max length of fact, not necessary to run\n",
    "max_l, min_l = 0, 999999999999\n",
    "max_words, min_words = 0, 999999999999\n",
    "for fact in facts:\n",
    "    max_l, min_l = max(max_l, len(fact)), min(min_l, len(fact))\n",
    "    c = fact.count(\" \")\n",
    "    max_words, min_words = max(max_words, c), min(min_words, c)\n",
    "print(max_l, min_l)\n",
    "print(max_words, min_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Encode dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model_name = 'msmarco-distilbert-base-v4'\n",
    "# model_name = \"multi-qa-MiniLM-L6-cos-v1\"\n",
    "model_name = 'all-mpnet-base-v2'\n",
    "model = SentenceTransformer(model_name, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61994d712e4c4b869ea25f8b1b3f9ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/163542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = model.encode(facts, device='cuda', show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'emb_hotpot_{model_name}.pickle', 'wb') as f:\n",
    "    pickle.dump(embeddings, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'all-mpnet-base-v2'\n",
    "with open(f'emb_hotpot_{model_name}.pickle', 'rb') as f:\n",
    "    embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Create index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "d = embeddings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index_flatip = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "# index_flatip.add(embeddings)\n",
    "# sys.getsizeof(index_flatip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "quant = faiss.IndexFlatL2(d)\n",
    "index_ivfpqflat = faiss.IndexIVFPQ(quant, d, 100, 8, 8)\n",
    "index_ivfpqflat.train(embeddings)\n",
    "index_ivfpqflat.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# quant = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "# index_ivfflat = faiss.IndexIVFFlat(quant, embeddings.shape[1], 100)\n",
    "# index_ivfflat.train(embeddings)\n",
    "# index_ivfflat.add(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index_name = \"index_ivfpqflat\"\n",
    "with open(f'{index_name}_hotpot_{model_name}.pickle', 'wb') as f:\n",
    "    pickle.dump(index_ivfpqflat, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index_name = \"index_ivfpqflat\"\n",
    "model_name = 'all-mpnet-base-v2'\n",
    "with open(f'{index_name}_hotpot_{model_name}.pickle', 'rb') as f:\n",
    "    index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test retrievers against each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_sample(sample, fact_sets, questions_sets, index1, index2, model1, model2, prtlvl=0):\n",
    "    hits_sum = {'1': 0, '2': 0}\n",
    "    versions = [(model1, index1), (model2, index2)]\n",
    "\n",
    "    for i in sample:\n",
    "        q, target_facts = questions_sets[i][\"text\"], questions_sets[i][\"metadata\"][\"supporting_facts\"]\n",
    "\n",
    "        for vi, (model, index) in enumerate(versions):\n",
    "            D, I = index.search(model.encode([q]), k)\n",
    "            f = [fact_sets[j]['title'] for j in I[0]]\n",
    "            ft = [fact[0] for fact in target_facts]\n",
    "            hits = len(list(set(f) & set(ft)))\n",
    "            hits_sum[str(vi+1)] += hits\n",
    "            if prtlvl > 0:\n",
    "                if vi == 0 or prtlvl > 2: print(q)\n",
    "                print(\"  retrieved: \" + str(f))\n",
    "                print(\"  target: \" + str(ft))\n",
    "                print(\"  hits: \" + str(hits))\n",
    "\n",
    "                if prtlvl > 1:\n",
    "                    for j in I[0]:\n",
    "                        print(f\"    -> {fact_sets[j]['title']} - {fact_sets[j]['text']}\\n\")\n",
    "\n",
    "\n",
    "                if vi < len(versions) - 1:\n",
    "                    print(\"  \" + \"*\" * 50)\n",
    "                else:\n",
    "                    print(\"-\" * 100)\n",
    "    print(hits_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model2_name = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "model2 = SentenceTransformer(model2_name, device='cuda')\n",
    "index2_name = \"index_ivfpq\"\n",
    "\n",
    "with open(f'{index2_name}_hotpot_{model2_name}.pickle', 'rb') as f:\n",
    "    index2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "n_qs = 50\n",
    "sample = random.sample(range(len(questions)), n_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 11, '2': 12}\n"
     ]
    }
   ],
   "source": [
    "test_sample(sample, fact_sets, questions_sets, index, index2, model, model2, prtlvl=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dump/load embeddings in batch files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_batched_embs(embeddings, directory, batch_volume):\n",
    "    required_space_gb = embeddings.shape[0] * embeddings.shape[1] * 4 / batch_volume\n",
    "    batch_size =  int(np.ceil(batch_volume / (embeddings.shape[1] * 4))) # n of rows that is 1 gbs of data\n",
    "    n_batches = int(np.ceil(embeddings.shape[0] / batch_size))\n",
    "    print(f\"Required space: {required_space_gb}, {n_batches} of files with {batch_size} embeddings each and filesize {batch_volume / 1000000000} GB\")\n",
    "    batch_indexes = [(batch_size*x, batch_size*(x+1)) for x in range(n_batches)]\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    for i, (lower, upper) in tqdm(enumerate(batch_indexes)):\n",
    "        fdir = f\"{directory}/{str(i).zfill(3)}.pickle\"\n",
    "        emb_batch = embeddings[lower:upper]\n",
    "\n",
    "        with open(fdir, 'wb') as f:\n",
    "            pickle.dump(emb_batch, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_all_batched_embs(directory):\n",
    "    files = os.listdir(directory)\n",
    "    files.sort()\n",
    "    embeddings = []\n",
    "    for f in tqdm(files):\n",
    "        with open(f\"{directory}/{f}\", 'rb') as f:\n",
    "            embeddings.append(pickle.load(f))\n",
    "    return np.concatenate(embeddings)\n",
    "\n",
    "# generator returning batches of embeddings from directory\n",
    "def batched_embs_generator(directory):\n",
    "    files = os.listdir(directory)\n",
    "    files.sort()\n",
    "    for f in files:\n",
    "        with open(f\"{directory}/{f}\", 'rb') as f:\n",
    "            yield pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'all-mpnet-base-v2'\n",
    "batch_volume = 1000000000 # size in bytes\n",
    "directory = f\"./emb_hotpot_{model_name}_b\"\n",
    "\n",
    "save_batched_embs(embeddings, directory, batch_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train index from batched embeddings files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:46,  2.73s/it]\n"
     ]
    }
   ],
   "source": [
    "# initiate index\n",
    "d = 768 # embedding length\n",
    "quant = faiss.IndexFlatL2(d)\n",
    "index_batched = faiss.IndexIVFPQ(quant, d, 100, 8, 8)\n",
    "\n",
    "# train in batches\n",
    "gen = batched_embs_generator(directory)\n",
    "for i, emb_batch in tqdm(enumerate(gen)):\n",
    "    if i==0:\n",
    "        index_batched.train(emb_batch)\n",
    "    index_batched.add(emb_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
