{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in c:\\users\\dawid.plaskowski\\anaconda3\\envs\\piqard\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\dawid.plaskowski\\anaconda3\\envs\\piqard\\lib\\site-packages (from wikipedia) (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dawid.plaskowski\\anaconda3\\envs\\piqard\\lib\\site-packages (from wikipedia) (4.11.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dawid.plaskowski\\anaconda3\\envs\\piqard\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\dawid.plaskowski\\anaconda3\\envs\\piqard\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dawid.plaskowski\\anaconda3\\envs\\piqard\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dawid.plaskowski\\anaconda3\\envs\\piqard\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dawid.plaskowski\\anaconda3\\envs\\piqard\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.3.2.post1)\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import wikipedia\n",
    "import re\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bloom():\n",
    "    def __init__(self, api_key: str):\n",
    "        self.API_URL = \"https://api-inference.huggingface.co/models/bigscience/bloom\"\n",
    "        self.API_KEY = api_key\n",
    "        self.headers = {\"Authorization\": f\"Bearer {self.API_KEY}\"}\n",
    "\n",
    "    def query(self, payload: str) -> str:\n",
    "        response = requests.post(self.API_URL, headers=self.headers, json=payload)\n",
    "        return response.json()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"BLOOM 176b huggingface.co API\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colored(st, color): return f\"\\u001b[{30+['black', 'red', 'green', 'yellow', 'blue', 'magenta', 'cyan', 'white'].index(color)}m{st}\\u001b[0m\"\n",
    "\n",
    "def search_wikipedia(query: str, num_sentences: int = 2, verbose: bool = False) -> str:\n",
    "    try:\n",
    "        return wikipedia.summary(query, sentences=num_sentences)\n",
    "    except wikipedia.exceptions.PageError as e:\n",
    "        possible_results = wikipedia.search(query)\n",
    "        if verbose:\n",
    "            for i, topic in enumerate(possible_results):\n",
    "                print(f\"{i+1}. {topic}\")\n",
    "        return wikipedia.summary(possible_results[0], sentences=num_sentences)\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        possible_results = wikipedia.search(query)\n",
    "        if verbose:\n",
    "            for i, topic in enumerate(possible_results):\n",
    "                print(f\"{i+1}. {topic}\")\n",
    "        return wikipedia.summary(possible_results[0], sentences=num_sentences)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChainTrace, Action, Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChainTrace:\n",
    "  __type_of_nodes = ['base_prompt', 'thought', 'action', 'observation', 'finish']\n",
    "  __color_mapping = {'base_prompt': 'white', 'thought': 'blue', 'action': 'red', 'observation': 'yellow', 'finish': 'green'}\n",
    "  \n",
    "  def __init__(self, data: str, type_of_node: str, depth: int = 0) -> None:\n",
    "    assert type_of_node in self.__type_of_nodes, f\"Type of node must be one of {self.__type_of_nodes}\"\n",
    "    self.type_of_node = type_of_node   \n",
    "    self.depth = depth\n",
    "    if self.depth == 0:\n",
    "      assert self.type_of_node == 'base_prompt', f\"Type of node must be 'base_prompt' for depth 0\"\n",
    "    self.next = None\n",
    "    self.data = data\n",
    "    self.is_leaf = False\n",
    "    if(self.type_of_node == 'finish'):\n",
    "      self.is_leaf = True\n",
    "      \n",
    "  def add(self, data: str, type_of_node: str) -> None:\n",
    "    if self.is_leaf:\n",
    "      raise Exception(\"Cannot add to a leaf node\")\n",
    "    if self.next is None:\n",
    "      self.next = ChainTrace(data, type_of_node, self.depth+1)\n",
    "    else:\n",
    "      self.next.add(data, type_of_node)\n",
    "      \n",
    "  def compose(self) -> str:\n",
    "    if self.is_leaf or self.next is None:\n",
    "      return self.data\n",
    "    else:\n",
    "      return self.data + self.next.compose()\n",
    "      \n",
    "  def get_max_depth(self) -> int:\n",
    "    if self.is_leaf == True or self.next is None:\n",
    "      return self.depth\n",
    "    else:\n",
    "      return self.next.get_max_depth()\n",
    "    \n",
    "  def get_deepest_node(self):\n",
    "    if self.next is None:\n",
    "      return self\n",
    "    else:\n",
    "      return self.next.get_deepest_node()\n",
    "    \n",
    "  def __str__(self) -> str:\n",
    "    trace = ''\n",
    "    trace += colored(self.data, self.__color_mapping[self.type_of_node])\n",
    "    while self.next is not None:\n",
    "      self = self.next\n",
    "      trace += colored(self.data, self.__color_mapping[self.type_of_node])\n",
    "    return trace\n",
    "\n",
    "  def __len__(self) -> int:\n",
    "    return len(self.compose())\n",
    "   \n",
    "@dataclass\n",
    "class Action:\n",
    "  name: str\n",
    "  func: Callable[[str], str]\n",
    "  prefix: str\n",
    "\n",
    "  def check(self, input: str) -> bool:\n",
    "    \"\"\"\n",
    "      Check if the action is appropriate for the given action by comparing prefix attribute with input in form: 'Action: Prefix[When was Aristotle born?]'\n",
    "    \"\"\"\n",
    "    regex_rule = f\"{self.prefix}\\[.*?\\]\"\n",
    "    if len(re.findall(regex_rule, input)) != 0 and len(re.findall(regex_rule, input)) == 1:\n",
    "      return True\n",
    "    return False\n",
    "\n",
    "  def extract_query(self, input: str) -> str:\n",
    "    \"\"\"\n",
    "      This method checks if the input has a matching command for the action and then extracts the inside of the command\n",
    "      For an input with a command e.g 'Action 1: Search[When was Aristotle born?]' should return: When was Aristotle born?\n",
    "    \"\"\"\n",
    "    rule_for_cleaning = f\"{self.prefix}\\[.*?\\]\"\n",
    "    cleaned_input = re.findall(rule_for_cleaning, input)\n",
    "    assert len(cleaned_input) != 0, f\"Did not find a matching command in the input: {input}\"\n",
    "    assert len(cleaned_input) == 1, f\"Input has multiple commands input: {input}\"\n",
    "    cleaned_input = cleaned_input[0].replace(self.prefix+'[', '').replace(']', '')\n",
    "    return cleaned_input\n",
    "    \n",
    "  def __call__(self, input: str):\n",
    "    \"\"\"\n",
    "      The call should receive input in command form, e.g.: 'Search[When was Aristotle born?]'\n",
    "      Then passes extracted content, e.g. When was Aristotle born?\n",
    "    \"\"\"\n",
    "    query = self.extract_query(input)\n",
    "    return self.func(query)\n",
    "\n",
    "class Agent:\n",
    "  \"\"\" An agent implementing \"ReAct: Synergizing Reasoning and Acting in Language Models, Yao 2022\"\n",
    "  \"\"\"\n",
    "  def __init__(self, prompt: str, actions: List[Action]) -> None:\n",
    "    self.llm = Bloom(API_KEY)\n",
    "    self.base_prompt = prompt   \n",
    "    self.actions = actions \n",
    "    self.sequence_stopper = Action(name=\"Sequence stopper\", func=lambda x: x, prefix=\"Finish\")\n",
    "    self.trace = None\n",
    "    \n",
    "  def run(self, user_question: str):\n",
    "    input = self.base_prompt.format(user_question=user_question)\n",
    "    self.trace = ChainTrace(input, 'base_prompt') # initialize the trace with the base prompt\n",
    "    output = self.llm.query(input)[0][\"generated_text\"]\n",
    "    intermediate_answer = output[len(self.trace):]\n",
    "    print(intermediate_answer)\n",
    "    \n",
    "    max_iterations = 20\n",
    "    flag = True\n",
    "    while flag and max_iterations > 0:\n",
    "      max_iterations -= 1\n",
    "      for i, generated_line in enumerate(intermediate_answer.split('\\n')):\n",
    "        # TODO: add \"Thought\" at the beginning of the line for the first thought\n",
    "        if generated_line.startswith('Thought') and generated_line.endswith('\\n'):\n",
    "          self.trace.add(generated_line+'\\n', 'thought') \n",
    "               \n",
    "        elif generated_line.startswith('Thought') and not generated_line.endswith('\\n'):\n",
    "          completed_thought = self.llm.query(self.trace.compose()+generated_line)[0][\"generated_text\"]\n",
    "          completed_thought = completed_thought[len(self.trace):].split('\\n')[0]\n",
    "          self.trace.add(completed_thought+'\\n', 'thought')\n",
    "          \n",
    "        elif generated_line.startswith('Action') and not generated_line.endswith('\\n'):\n",
    "          completed_action = self.llm.query(self.trace.compose()+generated_line)[0][\"generated_text\"]\n",
    "          completed_action = completed_action[len(self.trace):].split('\\n')[0]\n",
    "          self.trace.add(completed_action+'\\n', 'action')\n",
    "          if self.sequence_stopper.check(completed_action):\n",
    "            final_answer = self.sequence_stopper(completed_action)\n",
    "            self.trace.add(final_answer+'\\n', 'finish')\n",
    "            flag = False\n",
    "            break\n",
    "          for action in self.actions:\n",
    "            if action.check(completed_action):\n",
    "              retrieved_context = action(completed_action)\n",
    "              retrieved_context = f\"Observation: {retrieved_context}\"\n",
    "              self.trace.add(retrieved_context+'\\n', 'observation')\n",
    "              \n",
    "        elif generated_line.startswith('Action') and generated_line.endswith('\\n'):\n",
    "          self.trace.add(generated_line+'\\n', 'action')\n",
    "          if self.sequence_stopper.check(completed_action):\n",
    "            final_answer = self.sequence_stopper(completed_action)\n",
    "            self.trace.add(final_answer+'\\n', 'finish')\n",
    "            flag = False\n",
    "            break\n",
    "          for action in self.actions:\n",
    "            if action.check(generated_line):\n",
    "              retrieved_context = action(generated_line)\n",
    "              self.trace.add(retrieved_context+'\\n', 'observation')\n",
    "\n",
    "      intermediate_answer = self.llm.query({\"inputs\":self.trace.compose(), \"return_full_text\": False})[0][\"generated_text\"] # should add intermidiate answer to the trace?\n",
    "      intermediate_answer = intermediate_answer[len(self.trace):]\n",
    "      print(colored(intermediate_answer, 'black'))\n",
    "    print(self.trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "react_prompt = \"\"\"Question: What profession does Nicholas Ray and Elia Kazan have in common?\n",
    "Thought 1: I need to search Nicholas Ray and Elia Kazan, find their professions, then find the profession they have in common.\n",
    "Action 1: Search[Nicholas Ray]\n",
    "Observation: Nicholas Ray (born Raymond Nicholas Kienzle Jr., August 7, 1911 - June 16, 1979) was an American film director, screenwriter, and actor best known for the 1955 film Rebel Without a Cause.\n",
    "Thought 2: Professions of Nicholas Ray are director, screenwriter, and actor. I need to search Elia Kazan next and find his professions.\n",
    "Action 2: Search[Elia Kazan]\n",
    "Observation: Elia Kazan was an American film and theatre director, producer, screenwriter and actor.\n",
    "Thought 3: Professions of Elia Kazan are director, producer, screenwriter, and actor. So profession Nicholas Ray and Elia Kazan have in common is director, screenwriter, and actor.\n",
    "Action 3: Finish[director, screenwriter, actor]\n",
    "---\n",
    "Question: Which magazine was started first Arthur’s Magazine or First for Women?\n",
    "Thought 1: I need to search Arthur’s Magazine and First for Women, and find which was started first.\n",
    "Action 1: Search[Arthur’s Magazine]\n",
    "Observation: Arthur’s Magazine (1844-1846) was an American literary periodical published in Philadelphia in the 19th century.\n",
    "Thought 2: Arthur’s Magazine was started in 1844. I need to search First for Women next.\n",
    "Action 2: Search[First for Women]\n",
    "Observation: First for Women is a woman’s magazine published by Bauer Media Group in the USA.[1] The magazine was started in 1989.\n",
    "Thought 3: First for Women was started in 1989. 1844 < 1989, so Arthur’s Magazine was started first.\n",
    "Action 3: Finish[Arthur’s Magazine]\n",
    "---\n",
    "Question: Were Pavel Urysohn and Leonid Levin known for the same type of work?\n",
    "Thought 1: I need to search Pavel Urysohn and Leonid Levin, find their types of work, then find if they are the same.\n",
    "Action 1: Search[Pavel Urysohn]\n",
    "Observation: Pavel Samuilovich Urysohn (February 3, 1898 - August 17, 1924) was a Soviet mathematician who is best known for his contributions in dimension theory.\n",
    "Thought 2: Pavel Urysohn is a mathematician. I need to search Leonid Levin next and find its type of work.\n",
    "Action 2: Search[Leonid Levin]\n",
    "Observation: Leonid Anatolievich Levin is a Soviet-American mathematician and computer scientist.\n",
    "Thought 3: Leonid Levin is a mathematician and computer scientist. So Pavel Urysohn and Leonid Levin have the same type of work.\n",
    "Action 3: Finish[yes]\n",
    "---\n",
    "Question: {user_question}\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = Action(name=\"Wikipedia\", func=search_wikipedia, prefix=\"Search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(prompt=react_prompt, actions=[wiki])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought 1: I need to search Finnish rock groups, Adam Clayton Powell, and The Saima\n",
      "\u001b[30mAction 1: Search[Finnish rock groups]\n",
      "Observation: Finnish rock groups is a Finnish rock\u001b[0m\n",
      "\u001b[30mThought 2: Finnish rock groups are Adam Clayton Powell and The Saimaa Gesture. I\u001b[0m\n",
      "\u001b[30mAction 2: Search[Adam Clayton Powell]\n",
      "Observation: Adam Clayton Powell Jr. (born August\u001b[0m\n",
      "\u001b[30mThought 3: Finnish rock groups are Adam Clayton Powell and The Saimaa Gesture. So\u001b[0m\n",
      "\u001b[30mAction 3: Finish[Adam Clayton Powell]\n",
      "---\n",
      "Question: Which of the following is a type\u001b[0m\n",
      "\u001b[30m---\n",
      "Question: Which of these is a type of music, rock and roll or rockabilly?\n",
      "\u001b[0m\n",
      "\u001b[37mQuestion: What profession does Nicholas Ray and Elia Kazan have in common?\n",
      "Thought 1: I need to search Nicholas Ray and Elia Kazan, find their professions, then find the profession they have in common.\n",
      "Action 1: Search[Nicholas Ray]\n",
      "Observation: Nicholas Ray (born Raymond Nicholas Kienzle Jr., August 7, 1911 - June 16, 1979) was an American film director, screenwriter, and actor best known for the 1955 film Rebel Without a Cause.\n",
      "Thought 2: Professions of Nicholas Ray are director, screenwriter, and actor. I need to search Elia Kazan next and find his professions.\n",
      "Action 2: Search[Elia Kazan]\n",
      "Observation: Elia Kazan was an American film and theatre director, producer, screenwriter and actor.\n",
      "Thought 3: Professions of Elia Kazan are director, producer, screenwriter, and actor.\n",
      "So profession Nicholas Ray and Elia Kazan have in common is director, screenwriter, and actor.\n",
      "Action 3: Finish[director, screenwriter, actor]\n",
      "---\n",
      "Question: Which magazine was started first Arthur’s Magazine or First for Women?\n",
      "Thought 1: I need to search Arthur’s Magazine and First for Women, and find which was started first.\n",
      "Action 1: Search[Arthur’s Magazine]\n",
      "Observation: Arthur’s Magazine (1844-1846) was an American literary periodical published in Philadelphia in the 19th century.\n",
      "Thought 2: Arthur’s Magazine was started in 1844. I need to search First for Women next.\n",
      "Action 2: Search[First for Women]\n",
      "Observation: First for Women is a woman’s magazine published by Bauer Media Group in the USA.[1] The magazine was started in 1989.\n",
      "Thought 3: First for Women was started in 1989. 1844 < 1989, so Arthur’s Magazine was started first.\n",
      "Action 3: Finish[Arthur’s Magazine]\n",
      "---\n",
      "Question: Were Pavel Urysohn and Leonid Levin known for the same type of work?\n",
      "Thought 1: I need to search Pavel Urysohn and Leonid Levin, find their types of work, then find if they are the same.\n",
      "Action 1: Search[Pavel Urysohn]\n",
      "Observation: Pavel Samuilovich Urysohn (February 3, 1898 - August 17, 1924) was a Soviet mathematician who is best known for his contributions in dimension theory.\n",
      "Thought 2: Pavel Urysohn is a mathematician. I need to search Leonid Levin next and find its type of work.\n",
      "Action 2: Search[Leonid Levin]\n",
      "Observation: Leonid Anatolievich Levin is a Soviet-American mathematician and computer scientist.\n",
      "Thought 3: Leonid Levin is a mathematician and computer scientist. So Pavel Urysohn and Leonid Levin have the same type of work.\n",
      "Action 3: Finish[yes]\n",
      "---\n",
      "Question: Which documentary is about Finnish rock groups, Adam Clayton Powell or The Saimaa Gesture?\n",
      "\u001b[0m\u001b[34mThought 1: I need to search Finnish rock groups, Adam Clayton Powell, and The Saimaa Gesture, and find which is about Finnish rock groups.\n",
      "\u001b[0m\u001b[31mAction 1: Search[Finnish rock groups]\n",
      "\u001b[0m\u001b[33mObservation: Finnish rock (Finnish: suomirock or suomirokki—also known as Finnsrock, Finnrock or Finrock) refers to rock music made in Finland. The initial rock and roll boom of the 1950s was preceded by a long tradition of popular culture.\n",
      "\u001b[0m\u001b[34mThought 2: Finnish rock groups are Adam Clayton Powell and The Saimaa Gesture. I need to search Adam Clayton Powell next.\n",
      "\u001b[0m\u001b[31mAction 2: Search[Adam Clayton Powell]\n",
      "\u001b[0m\u001b[33mObservation: Adam Clayton Powell Jr. (November 29, 1908 – April 4, 1972) was an American Baptist pastor and politician who represented the Harlem neighborhood of New York City in the United States House of Representatives from 1945 until 1971.\n",
      "\u001b[0m\u001b[34mThought 3: Finnish rock groups are Adam Clayton Powell and The Saimaa Gesture. So Adam Clayton Powell is about Finnish rock groups.\n",
      "\u001b[0m\u001b[31mAction 3: Finish[Adam Clayton Powell]\n",
      "\u001b[0m\u001b[32mAdam Clayton Powell\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent.run(\"Which documentary is about Finnish rock groups, Adam Clayton Powell or The Saimaa Gesture?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "ename": "PageError",
     "evalue": "Page id \"unit 231\" does not match any pages. Try another id!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPageError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [290], line 5\u001b[0m, in \u001b[0;36msearch_wikipedia\u001b[1;34m(query, num_sentences, verbose)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m     \u001b[39mreturn\u001b[39;00m wikipedia\u001b[39m.\u001b[39;49msummary(query, sentences\u001b[39m=\u001b[39;49mnum_sentences)\n\u001b[0;32m      6\u001b[0m \u001b[39mexcept\u001b[39;00m wikipedia\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mPageError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\util.py:28\u001b[0m, in \u001b[0;36mcache.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m   ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache[key] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     30\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\wikipedia.py:231\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(title, sentences, chars, auto_suggest, redirect)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39m# use auto_suggest and redirect to get the correct article\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[39m# also, use page's error checking to raise DisambiguationError if necessary\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m page_info \u001b[39m=\u001b[39m page(title, auto_suggest\u001b[39m=\u001b[39;49mauto_suggest, redirect\u001b[39m=\u001b[39;49mredirect)\n\u001b[0;32m    232\u001b[0m title \u001b[39m=\u001b[39m page_info\u001b[39m.\u001b[39mtitle\n",
      "File \u001b[1;32mc:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\wikipedia.py:276\u001b[0m, in \u001b[0;36mpage\u001b[1;34m(title, pageid, auto_suggest, redirect, preload)\u001b[0m\n\u001b[0;32m    275\u001b[0m       \u001b[39mraise\u001b[39;00m PageError(title)\n\u001b[1;32m--> 276\u001b[0m   \u001b[39mreturn\u001b[39;00m WikipediaPage(title, redirect\u001b[39m=\u001b[39;49mredirect, preload\u001b[39m=\u001b[39;49mpreload)\n\u001b[0;32m    277\u001b[0m \u001b[39melif\u001b[39;00m pageid \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\wikipedia.py:299\u001b[0m, in \u001b[0;36mWikipediaPage.__init__\u001b[1;34m(self, title, pageid, redirect, preload, original_title)\u001b[0m\n\u001b[0;32m    297\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mEither a title or a pageid must be specified\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 299\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__load(redirect\u001b[39m=\u001b[39;49mredirect, preload\u001b[39m=\u001b[39;49mpreload)\n\u001b[0;32m    301\u001b[0m \u001b[39mif\u001b[39;00m preload:\n",
      "File \u001b[1;32mc:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\wikipedia.py:345\u001b[0m, in \u001b[0;36mWikipediaPage.__load\u001b[1;34m(self, redirect, preload)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 345\u001b[0m   \u001b[39mraise\u001b[39;00m PageError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtitle)\n\u001b[0;32m    346\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mPageError\u001b[0m: Page id \"nicholas ray\" does not match any pages. Try another id!",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPageError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [299], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m search_wikipedia(\u001b[39m\"\u001b[39;49m\u001b[39mNicholar Ray\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn [290], line 11\u001b[0m, in \u001b[0;36msearch_wikipedia\u001b[1;34m(query, num_sentences, verbose)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[39mfor\u001b[39;00m i, topic \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(possible_results):\n\u001b[0;32m     10\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m{\u001b[39;00mtopic\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m     \u001b[39mreturn\u001b[39;00m wikipedia\u001b[39m.\u001b[39;49msummary(possible_results[\u001b[39m0\u001b[39;49m], sentences\u001b[39m=\u001b[39;49mnum_sentences)\n\u001b[0;32m     12\u001b[0m \u001b[39mexcept\u001b[39;00m wikipedia\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mDisambiguationError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     13\u001b[0m     possible_results \u001b[39m=\u001b[39m wikipedia\u001b[39m.\u001b[39msearch(query)\n",
      "File \u001b[1;32mc:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\util.py:28\u001b[0m, in \u001b[0;36mcache.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m   ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache[key]\n\u001b[0;32m     27\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m   ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache[key] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     30\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\wikipedia.py:231\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(title, sentences, chars, auto_suggest, redirect)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[39mPlain text summary of the page.\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39m* redirect - allow redirection without raising RedirectError\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[39m# use auto_suggest and redirect to get the correct article\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[39m# also, use page's error checking to raise DisambiguationError if necessary\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m page_info \u001b[39m=\u001b[39m page(title, auto_suggest\u001b[39m=\u001b[39;49mauto_suggest, redirect\u001b[39m=\u001b[39;49mredirect)\n\u001b[0;32m    232\u001b[0m title \u001b[39m=\u001b[39m page_info\u001b[39m.\u001b[39mtitle\n\u001b[0;32m    233\u001b[0m pageid \u001b[39m=\u001b[39m page_info\u001b[39m.\u001b[39mpageid\n",
      "File \u001b[1;32mc:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\wikipedia.py:276\u001b[0m, in \u001b[0;36mpage\u001b[1;34m(title, pageid, auto_suggest, redirect, preload)\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m       \u001b[39m# if there is no suggestion or search results, the page doesn't exist\u001b[39;00m\n\u001b[0;32m    275\u001b[0m       \u001b[39mraise\u001b[39;00m PageError(title)\n\u001b[1;32m--> 276\u001b[0m   \u001b[39mreturn\u001b[39;00m WikipediaPage(title, redirect\u001b[39m=\u001b[39;49mredirect, preload\u001b[39m=\u001b[39;49mpreload)\n\u001b[0;32m    277\u001b[0m \u001b[39melif\u001b[39;00m pageid \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    278\u001b[0m   \u001b[39mreturn\u001b[39;00m WikipediaPage(pageid\u001b[39m=\u001b[39mpageid, preload\u001b[39m=\u001b[39mpreload)\n",
      "File \u001b[1;32mc:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\wikipedia.py:299\u001b[0m, in \u001b[0;36mWikipediaPage.__init__\u001b[1;34m(self, title, pageid, redirect, preload, original_title)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mEither a title or a pageid must be specified\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 299\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__load(redirect\u001b[39m=\u001b[39;49mredirect, preload\u001b[39m=\u001b[39;49mpreload)\n\u001b[0;32m    301\u001b[0m \u001b[39mif\u001b[39;00m preload:\n\u001b[0;32m    302\u001b[0m   \u001b[39mfor\u001b[39;00m prop \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mreferences\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlinks\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msections\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\wikipedia.py:345\u001b[0m, in \u001b[0;36mWikipediaPage.__load\u001b[1;34m(self, redirect, preload)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mmissing\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m page:\n\u001b[0;32m    344\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 345\u001b[0m     \u001b[39mraise\u001b[39;00m PageError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtitle)\n\u001b[0;32m    346\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    347\u001b[0m     \u001b[39mraise\u001b[39;00m PageError(pageid\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpageid)\n",
      "\u001b[1;31mPageError\u001b[0m: Page id \"unit 231\" does not match any pages. Try another id!"
     ]
    }
   ],
   "source": [
    "search_wikipedia(\"Nicholar Ray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retreiver.get_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yellow is the color between green and orange on the spectrum of light. It is evoked by light with a dominant wavelength of roughly 575–585 nm.'"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_wikipedia(\"color yellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought 1: I need to search color yellow, find its meaning, then find what it is.\n",
      "\n",
      "\u001b[30mAction 1: Search[color yellow]\n",
      "Observation: Color yellow is a color in the visible spectrum.\u001b[0m\n",
      "\u001b[30mThought 2: Color yellow is evoked by light with a dominant wavelength of roughly 575–585 nm\u001b[0m\n",
      "\u001b[30mAction 2: Search[what it is]\n",
      "Observation: What it is is a question that is asked\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "ename": "DisambiguationError",
     "evalue": "\"What It Is\" may refer to: \nWhat It Is (Boogaloo Joe Jones album)\nCordelia's Dad\nWhat It Is (Mal Waldron album)\nWhat It Is (PSD album)\nWhat It Is (Jacky Terrasson album)\nWhat It Is!\nGrammy Award for Best Boxed or Special Limited Edition Package\n\"What It Is\" (Busta Rhymes song)\n\"What It Is\" (Gorilla Zoe song)\n\"What It Is\" (Jonathan Davis song)\n\"What It Is\" (Mark Knopfler song)\nWhat It Is (Strike a Pose)\nBehind the Front\nRun Devil Run\nDylan Moran\nLynda Barry\nAll pages with titles beginning with What It Is\nAll pages with titles containing What It Is\nIt Is What It Is (disambiguation)\nWhat is it (disambiguation)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDisambiguationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [290], line 5\u001b[0m, in \u001b[0;36msearch_wikipedia\u001b[1;34m(query, num_sentences, verbose)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m     \u001b[39mreturn\u001b[39;00m wikipedia\u001b[39m.\u001b[39;49msummary(query, sentences\u001b[39m=\u001b[39;49mnum_sentences)\n\u001b[0;32m      6\u001b[0m \u001b[39mexcept\u001b[39;00m wikipedia\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mPageError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\util.py:28\u001b[0m, in \u001b[0;36mcache.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m   ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache[key] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     30\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\wikipedia.py:231\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(title, sentences, chars, auto_suggest, redirect)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39m# use auto_suggest and redirect to get the correct article\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[39m# also, use page's error checking to raise DisambiguationError if necessary\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m page_info \u001b[39m=\u001b[39m page(title, auto_suggest\u001b[39m=\u001b[39;49mauto_suggest, redirect\u001b[39m=\u001b[39;49mredirect)\n\u001b[0;32m    232\u001b[0m title \u001b[39m=\u001b[39m page_info\u001b[39m.\u001b[39mtitle\n",
      "File \u001b[1;32mc:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\wikipedia.py:276\u001b[0m, in \u001b[0;36mpage\u001b[1;34m(title, pageid, auto_suggest, redirect, preload)\u001b[0m\n\u001b[0;32m    275\u001b[0m       \u001b[39mraise\u001b[39;00m PageError(title)\n\u001b[1;32m--> 276\u001b[0m   \u001b[39mreturn\u001b[39;00m WikipediaPage(title, redirect\u001b[39m=\u001b[39;49mredirect, preload\u001b[39m=\u001b[39;49mpreload)\n\u001b[0;32m    277\u001b[0m \u001b[39melif\u001b[39;00m pageid \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\wikipedia.py:299\u001b[0m, in \u001b[0;36mWikipediaPage.__init__\u001b[1;34m(self, title, pageid, redirect, preload, original_title)\u001b[0m\n\u001b[0;32m    297\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mEither a title or a pageid must be specified\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 299\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__load(redirect\u001b[39m=\u001b[39;49mredirect, preload\u001b[39m=\u001b[39;49mpreload)\n\u001b[0;32m    301\u001b[0m \u001b[39mif\u001b[39;00m preload:\n",
      "File \u001b[1;32mc:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\wikipedia.py:393\u001b[0m, in \u001b[0;36mWikipediaPage.__load\u001b[1;34m(self, redirect, preload)\u001b[0m\n\u001b[0;32m    391\u001b[0m   may_refer_to \u001b[39m=\u001b[39m [li\u001b[39m.\u001b[39ma\u001b[39m.\u001b[39mget_text() \u001b[39mfor\u001b[39;00m li \u001b[39min\u001b[39;00m filtered_lis \u001b[39mif\u001b[39;00m li\u001b[39m.\u001b[39ma]\n\u001b[1;32m--> 393\u001b[0m   \u001b[39mraise\u001b[39;00m DisambiguationError(\u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m, page[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m]), may_refer_to)\n\u001b[0;32m    395\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mDisambiguationError\u001b[0m: \"What It Is\" may refer to: \nWhat It Is (Boogaloo Joe Jones album)\nCordelia's Dad\nWhat It Is (Mal Waldron album)\nWhat It Is (PSD album)\nWhat It Is (Jacky Terrasson album)\nWhat It Is!\nGrammy Award for Best Boxed or Special Limited Edition Package\n\"What It Is\" (Busta Rhymes song)\n\"What It Is\" (Gorilla Zoe song)\n\"What It Is\" (Jonathan Davis song)\n\"What It Is\" (Mark Knopfler song)\nWhat It Is (Strike a Pose)\nBehind the Front\nRun Devil Run\nDylan Moran\nLynda Barry\nAll pages with titles beginning with What It Is\nAll pages with titles containing What It Is\nIt Is What It Is (disambiguation)\nWhat is it (disambiguation)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDisambiguationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [297], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m agent\u001b[39m.\u001b[39;49mrun(\u001b[39m\"\u001b[39;49m\u001b[39mWhat is color yellow?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn [291], line 129\u001b[0m, in \u001b[0;36mAgent.run\u001b[1;34m(self, user_question)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mfor\u001b[39;00m action \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactions:\n\u001b[0;32m    128\u001b[0m   \u001b[39mif\u001b[39;00m action\u001b[39m.\u001b[39mcheck(completed_action):\n\u001b[1;32m--> 129\u001b[0m     retrieved_context \u001b[39m=\u001b[39m action(completed_action)\n\u001b[0;32m    130\u001b[0m     retrieved_context \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mObservation: \u001b[39m\u001b[39m{\u001b[39;00mretrieved_context\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    131\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39madd(retrieved_context\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mobservation\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [291], line 86\u001b[0m, in \u001b[0;36mAction.__call__\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[39m  The call should receive input in command form, e.g.: 'Search[When was Aristotle born?]'\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39m  Then passes extracted content, e.g. When was Aristotle born?\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     85\u001b[0m query \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_query(\u001b[39minput\u001b[39m)\n\u001b[1;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(query)\n",
      "Cell \u001b[1;32mIn [290], line 17\u001b[0m, in \u001b[0;36msearch_wikipedia\u001b[1;34m(query, num_sentences, verbose)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[39mfor\u001b[39;00m i, topic \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(possible_results):\n\u001b[0;32m     16\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m{\u001b[39;00mtopic\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[39mreturn\u001b[39;00m wikipedia\u001b[39m.\u001b[39;49msummary(possible_results[\u001b[39m0\u001b[39;49m], sentences\u001b[39m=\u001b[39;49mnum_sentences)\n",
      "File \u001b[1;32mc:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\util.py:28\u001b[0m, in \u001b[0;36mcache.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m   ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache[key]\n\u001b[0;32m     27\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m   ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache[key] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     30\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\wikipedia.py:231\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(title, sentences, chars, auto_suggest, redirect)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[39mPlain text summary of the page.\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39m* redirect - allow redirection without raising RedirectError\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[39m# use auto_suggest and redirect to get the correct article\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[39m# also, use page's error checking to raise DisambiguationError if necessary\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m page_info \u001b[39m=\u001b[39m page(title, auto_suggest\u001b[39m=\u001b[39;49mauto_suggest, redirect\u001b[39m=\u001b[39;49mredirect)\n\u001b[0;32m    232\u001b[0m title \u001b[39m=\u001b[39m page_info\u001b[39m.\u001b[39mtitle\n\u001b[0;32m    233\u001b[0m pageid \u001b[39m=\u001b[39m page_info\u001b[39m.\u001b[39mpageid\n",
      "File \u001b[1;32mc:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\wikipedia.py:276\u001b[0m, in \u001b[0;36mpage\u001b[1;34m(title, pageid, auto_suggest, redirect, preload)\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m       \u001b[39m# if there is no suggestion or search results, the page doesn't exist\u001b[39;00m\n\u001b[0;32m    275\u001b[0m       \u001b[39mraise\u001b[39;00m PageError(title)\n\u001b[1;32m--> 276\u001b[0m   \u001b[39mreturn\u001b[39;00m WikipediaPage(title, redirect\u001b[39m=\u001b[39;49mredirect, preload\u001b[39m=\u001b[39;49mpreload)\n\u001b[0;32m    277\u001b[0m \u001b[39melif\u001b[39;00m pageid \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    278\u001b[0m   \u001b[39mreturn\u001b[39;00m WikipediaPage(pageid\u001b[39m=\u001b[39mpageid, preload\u001b[39m=\u001b[39mpreload)\n",
      "File \u001b[1;32mc:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\wikipedia.py:299\u001b[0m, in \u001b[0;36mWikipediaPage.__init__\u001b[1;34m(self, title, pageid, redirect, preload, original_title)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mEither a title or a pageid must be specified\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 299\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__load(redirect\u001b[39m=\u001b[39;49mredirect, preload\u001b[39m=\u001b[39;49mpreload)\n\u001b[0;32m    301\u001b[0m \u001b[39mif\u001b[39;00m preload:\n\u001b[0;32m    302\u001b[0m   \u001b[39mfor\u001b[39;00m prop \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mreferences\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlinks\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msections\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\dawid.plaskowski\\Anaconda3\\envs\\piqard\\lib\\site-packages\\wikipedia\\wikipedia.py:393\u001b[0m, in \u001b[0;36mWikipediaPage.__load\u001b[1;34m(self, redirect, preload)\u001b[0m\n\u001b[0;32m    390\u001b[0m   filtered_lis \u001b[39m=\u001b[39m [li \u001b[39mfor\u001b[39;00m li \u001b[39min\u001b[39;00m lis \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtocsection\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(li\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m, []))]\n\u001b[0;32m    391\u001b[0m   may_refer_to \u001b[39m=\u001b[39m [li\u001b[39m.\u001b[39ma\u001b[39m.\u001b[39mget_text() \u001b[39mfor\u001b[39;00m li \u001b[39min\u001b[39;00m filtered_lis \u001b[39mif\u001b[39;00m li\u001b[39m.\u001b[39ma]\n\u001b[1;32m--> 393\u001b[0m   \u001b[39mraise\u001b[39;00m DisambiguationError(\u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m, page[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m]), may_refer_to)\n\u001b[0;32m    395\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    396\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpageid \u001b[39m=\u001b[39m pageid\n",
      "\u001b[1;31mDisambiguationError\u001b[0m: \"What It Is\" may refer to: \nWhat It Is (Boogaloo Joe Jones album)\nCordelia's Dad\nWhat It Is (Mal Waldron album)\nWhat It Is (PSD album)\nWhat It Is (Jacky Terrasson album)\nWhat It Is!\nGrammy Award for Best Boxed or Special Limited Edition Package\n\"What It Is\" (Busta Rhymes song)\n\"What It Is\" (Gorilla Zoe song)\n\"What It Is\" (Jonathan Davis song)\n\"What It Is\" (Mark Knopfler song)\nWhat It Is (Strike a Pose)\nBehind the Front\nRun Devil Run\nDylan Moran\nLynda Barry\nAll pages with titles beginning with What It Is\nAll pages with titles containing What It Is\nIt Is What It Is (disambiguation)\nWhat is it (disambiguation)"
     ]
    }
   ],
   "source": [
    "agent.run(\"What is color yellow?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- semantic search as action \"Search\"\n",
    "- obsługa błędów dla wikipedia API\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
