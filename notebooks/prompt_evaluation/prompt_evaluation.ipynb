{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "from transformers import BloomTokenizerFast\n",
    "import json\n",
    "import requests\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import random\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model API"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "API_KEY = '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'\n",
    "\n",
    "class Bloom():\n",
    "    def __init__(self, api_key: str):\n",
    "        self.API_URL = \"https://api-inference.huggingface.co/models/bigscience/bloom\"\n",
    "        self.API_KEY = api_key\n",
    "        self.headers = {\"Authorization\": f\"Bearer {self.API_KEY}\"}\n",
    "\n",
    "    def query(self, payload: str) -> str:\n",
    "        response = requests.post(self.API_URL, headers=self.headers, json=payload)\n",
    "        return response.json()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"BLOOM 176b huggingface.co API\"\n",
    "\n",
    "def length_of_tokenized_prompt(prompt: str):\n",
    "    tokenizer = BloomTokenizerFast.from_pretrained(\"bigscience/bloom\")\n",
    "    tokenized_prompt = tokenizer(prompt)\n",
    "    return (len(tokenized_prompt[\"input_ids\"]))\n",
    "\n",
    "model = Bloom(API_KEY)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utils"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PromptCreator:\n",
    "    def __init__(self, start_instruction: str, questions: list, answered_question: dict, question_formatter):\n",
    "        self.start_instruction = start_instruction\n",
    "        self.questions = questions\n",
    "        self.question_formatter = question_formatter\n",
    "        self.answered_question = answered_question\n",
    "\n",
    "    def get_full_prompt(self):\n",
    "        result = f\"\"\"{self.start_instruction}\\n\\n\"\"\"\n",
    "        for i, question in enumerate(self.questions):\n",
    "            result += self.question_formatter(question, is_end=False) + \"\\n\"\n",
    "        result += self.question_formatter(self.answered_question, is_end=True)\n",
    "        return result\n",
    "\n",
    "    def add_question(self, question):\n",
    "        self.questions.append(question)\n",
    "\n",
    "    def set_answered_question(self, question):\n",
    "        self.answered_question = question\n",
    "\n",
    "def dict_from_list_by_key(list, key):\n",
    "    return {element[key]: element for element in list}\n",
    "\n",
    "def get_question_dict(q: dict, thoughts: list):\n",
    "    result = {\n",
    "        \"question\": q[\"question\"][\"stem\"],\n",
    "        \"possible_answers\": dict_from_list_by_key(q['question'][\"choices\"], \"label\"),\n",
    "        \"thoughts\": thoughts,\n",
    "        \"answer\": q[\"answerKey\"]\n",
    "    }\n",
    "    result[\"answer_text\"] = result[\"possible_answers\"][result[\"answer\"]][\"text\"]\n",
    "\n",
    "    return result\n",
    "\n",
    "def generate_text(prompt, max_iterations, stopword):\n",
    "    generated_text = prompt\n",
    "    for i in range(max_iterations):\n",
    "        last_len = len(generated_text)\n",
    "        generated_text = model.query(generated_text)[0]['generated_text']\n",
    "        generated_len = len(generated_text) - last_len\n",
    "        if stopword in generated_text[-generated_len:]: break\n",
    "    return generated_text\n",
    "\n",
    "def postprocess_answer(generated_text, stopword, final_answer_prompt):\n",
    "    answer = generated_text.split(prompt, 1)[-1]\n",
    "    answer = answer[answer.find(final_answer_prompt) + len(final_answer_prompt):]\n",
    "    answer = answer[:answer.find(stopword)].strip().strip(\"\\n\")\n",
    "    return answer\n",
    "\n",
    "def __normalize_answer(answer: str) -> str:\n",
    "    def remove_counter(text):\n",
    "        return (\n",
    "            text.replace(\"年\", \"\").replace(\"歳\", \"\").replace(\"人\", \"\").replace(\"년\", \"\")\n",
    "        )\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_counter(remove_punc(lower(answer))))\n",
    "\n",
    "def exact_match_score(prediction: str, ground_truth: str) -> int:\n",
    "    return __normalize_answer(prediction) == __normalize_answer(ground_truth)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "with open(\"Data/Main/train.jsonl\", \"r\") as f:\n",
    "    train_dict = dict_from_list_by_key([json.loads(line) for line in f], \"id\")\n",
    "\n",
    "with open(\"Data/Main/dev.jsonl\", \"r\") as f:\n",
    "    dev_dict = dict_from_list_by_key([json.loads(line) for line in f], \"id\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': '7-117',\n 'question': {'stem': 'There are producers that exist in the food chain, and they basically',\n  'choices': [{'text': 'are mainly creatures like deer', 'label': 'A'},\n   {'text': 'require photosynthesis to survive', 'label': 'B'},\n   {'text': 'produce a thing called chlorophyll', 'label': 'C'},\n   {'text': 'make good money at work', 'label': 'D'}]},\n 'answerKey': 'B'}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict[\"7-117\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "{'question': 'There are producers that exist in the food chain, and they basically',\n 'possible_answers': {'A': {'text': 'are mainly creatures like deer',\n   'label': 'A'},\n  'B': {'text': 'require photosynthesis to survive', 'label': 'B'},\n  'C': {'text': 'produce a thing called chlorophyll', 'label': 'C'},\n  'D': {'text': 'make good money at work', 'label': 'D'}},\n 'thoughts': ['Thought 1.', 'Thought 2.'],\n 'answer': 'B',\n 'answer_text': 'require photosynthesis to survive'}"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_question_dict(train_dict[\"7-117\"], [\"Thought 1.\", \"Thought 2.\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question Formatter\n",
    "tu tworzymy funkcję do przedstawiania pytań w prompterze"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def question_formatter_1(qdict: dict, is_end: bool):\n",
    "\n",
    "    possible_answers_str = ' '.join([choice[\"label\"] +\". \" + choice[\"text\"] for choice in qdict[\"possible_answers\"].values()])\n",
    "    answer_str =  f\"{qdict['answer']}. {qdict['answer_text']}\"\n",
    "\n",
    "    # ciąg chain of thoughts / faktów\n",
    "    thoughts_str = '\\n'.join([f\"Content: {th}\" for th in qdict[\"thoughts\"]])\n",
    "\n",
    "    if not is_end:\n",
    "        # pytania do fewshota\n",
    "        result = f\"\"\"Question: {qdict[\"question\"]}\n",
    "Possible answers: {possible_answers_str}\n",
    "Let's think step by step.\n",
    "{thoughts_str}\n",
    "Answer: {answer_str}\n",
    "\"\"\"\n",
    "    else:\n",
    "        # ostatnie pytanie, bez chain of thoughts\n",
    "        result = f\"\"\"Question: {qdict[\"question\"]}\n",
    "Possible answers: {possible_answers_str}\n",
    "Let's think step by step.\n",
    "\"\"\"\n",
    "    return result\n",
    "\n",
    "def question_formatter_2(qdict: dict, is_end: bool):\n",
    "\n",
    "    possible_answers_str = ' '.join([choice[\"label\"] +\". \" + choice[\"text\"] for choice in qdict[\"possible_answers\"].values()])\n",
    "    thoughts_str = '. '.join(qdict[\"thoughts\"])\n",
    "    answer_str =  f\"{qdict['answer']}. {qdict['answer_text']}\"\n",
    "\n",
    "\n",
    "    result = f\"\"\"QUESTION: {qdict[\"question\"]}\n",
    "POSSIBLE ANSWERS: {possible_answers_str}\n",
    "\"\"\"\n",
    "    if is_end:\n",
    "        result += \"====================\\nCONTEXT:\"\n",
    "        return result\n",
    "    else:\n",
    "        result += f\"\"\"====================\n",
    "CONTEXT: {thoughts_str}\n",
    "====================\n",
    "FINAL ANSWER: {answer_str}\n",
    "年\n",
    "\"\"\"\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# definicja pierwszej instrukcji, wybór przykładowych pytań oraz dodanie kontekstu do nich"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "start_instruction_1 = \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\"\n",
    "\n",
    "start_instruction_2 = \"Given the following extracted parts (\\\"Content\\\") of a long document and a question, choose a FINAL ANSWER from the POSSIBLE ANSWERS. If you don't know the answer, just say that you don't know. Don't try to make up an answer.\"\n",
    "\n",
    "start_instruction_3 = \"\"\"Use the given context and the possible answers provided to determine which one is the correct answer to the question. Keep in mind that the context may be noisy and not always directly relevant to the question, so use your judgment to determine the most appropriate answer.\"\"\"\n",
    "\n",
    "questions_and_thoughs = {\n",
    "    \"12-334\": [\n",
    "        \"Plant light emits light for plants to use\",\n",
    "        \"Plants don't have feelings so they don't need comfort\",\n",
    "        \"Plants use sunlight for producing nutrients\",\n",
    "        \"Light doesn't affect bugs\",\n",
    "        \"Light emitted by plant light does not produce big amounts of warmth\"],\n",
    "    \"12-416\": [\n",
    "        \"Positive impact on the bio environment\",\n",
    "        \"Toxic waste is harmful to the environment\",\n",
    "        \"Poisoned ground is not good for biological growth\",\n",
    "        \"Car fumes destroy the ozone layer\",\n",
    "        \"Recycling trash reduces waste on earth\",\n",
    "        \"Waste has a negative impact on environment\"],\n",
    "     \"12-541\": [\n",
    "        \"Digestion is the process of breaking down food\",\n",
    "        \"Pizza is food\",\n",
    "        \"A house is not food\",\n",
    "        \"A rock is not food\",\n",
    "        \"A car is not food\"],\n",
    "    \"12-470\": [\n",
    "        \"Warm potato has a lot of heat energy\",\n",
    "        \"Steel sink is a heat conductor\",\n",
    "        \"Burning happens when heat is added\",\n",
    "        \"Heat conductors remove heat from source\"],\n",
    "    \"12-509\": [\n",
    "        \"Things harmful to a human cause physical damage and pain\",\n",
    "        \"Dynamite creates high-energy explosions\",\n",
    "        \"Emails cannot cause damage to people\",\n",
    "        \"Balloons popping are loud but not harmful\",\n",
    "        \"Opening a soda releases low levels of energy from compressed gas\"],\n",
    "}\n",
    "\n",
    "answered_question_id = \"9-53\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# stworzenie promptu"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the given context and the possible answers provided to determine which one is the correct answer to the question. Keep in mind that the context may be noisy and not always directly relevant to the question, so use your judgment to determine the most appropriate answer.\n",
      "\n",
      "QUESTION: What purpose does a plant light serve?\n",
      "POSSIBLE ANSWERS: A. Comfort them B. replicate sunlight C. Protect from bugs D. Keep plants warm\n",
      "====================\n",
      "CONTEXT: Plant light emits light for plants to use. Plants don't have feelings so they don't need comfort. Plants use sunlight for producing nutrients. Light doesn't affect bugs. Light emitted by plant light does not produce big amounts of warmth\n",
      "====================\n",
      "FINAL ANSWER: B. replicate sunlight\n",
      "年\n",
      "\n",
      "QUESTION: Which is a positive impact on the bio environment?\n",
      "POSSIBLE ANSWERS: A. dumping toxic waste in rivers B. contaminating the ground with poison C. building cars in large numbers D. making sure trash is reused for new reasons\n",
      "====================\n",
      "CONTEXT: Positive impact on the bio environment. Toxic waste is harmful to the environment. Poisoned ground is not good for biological growth. Car fumes destroy the ozone layer. Recycling trash reduces waste on earth. Waste has a negative impact on environment\n",
      "====================\n",
      "FINAL ANSWER: D. making sure trash is reused for new reasons\n",
      "年\n",
      "\n",
      "QUESTION: Digestion is when stomach acid breaks down\n",
      "POSSIBLE ANSWERS: A. a pizza B. a house C. a rock D. a car\n",
      "====================\n",
      "CONTEXT: Digestion is the process of breaking down food. Pizza is food. A house is not food. A rock is not food. A car is not food\n",
      "====================\n",
      "FINAL ANSWER: A. a pizza\n",
      "年\n",
      "\n",
      "QUESTION: If a warm potato is left on a steel sink, the potato will\n",
      "POSSIBLE ANSWERS: A. burn B. lose heat C. get hotter D. warm up\n",
      "====================\n",
      "CONTEXT: Warm potato has a lot of heat energy. Steel sink is a heat conductor. Burning happens when heat is added. Heat conductors remove heat from source\n",
      "====================\n",
      "FINAL ANSWER: B. lose heat\n",
      "年\n",
      "\n",
      "QUESTION: Which is most harmful to a human?\n",
      "POSSIBLE ANSWERS: A. dynamite going off B. reading email C. balloons popping D. opening a soda\n",
      "====================\n",
      "CONTEXT: Things harmful to a human cause physical damage and pain. Dynamite creates high-energy explosions. Emails cannot cause damage to people. Balloons popping are loud but not harmful. Opening a soda releases low levels of energy from compressed gas\n",
      "====================\n",
      "FINAL ANSWER: A. dynamite going off\n",
      "年\n",
      "\n",
      "QUESTION: Water boiling in a pot on a stove is an example of\n",
      "POSSIBLE ANSWERS: A. electrocution B. freezing C. hydroplaning D. thermal conduction\n",
      "====================\n",
      "CONTEXT:\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    get_question_dict(train_dict[qid], thoughts)\n",
    "    for qid, thoughts in questions_and_thoughs.items()]\n",
    "answered_question = get_question_dict(dev_dict[answered_question_id], [])\n",
    "\n",
    "pcreator = PromptCreator(start_instruction_3, questions, answered_question, question_formatter_2)\n",
    "prompt = pcreator.get_full_prompt()\n",
    "print(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generowanie tekstu i odpowiedzi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the given context and the possible answers provided to determine which one is the correct answer to the question. Keep in mind that the context may be noisy and not always directly relevant to the question, so use your judgment to determine the most appropriate answer.\n",
      "\n",
      "QUESTION: What purpose does a plant light serve?\n",
      "POSSIBLE ANSWERS: A. Comfort them B. replicate sunlight C. Protect from bugs D. Keep plants warm\n",
      "====================\n",
      "CONTEXT: Plant light emits light for plants to use. Plants don't have feelings so they don't need comfort. Plants use sunlight for producing nutrients. Light doesn't affect bugs. Light emitted by plant light does not produce big amounts of warmth\n",
      "====================\n",
      "FINAL ANSWER: B. replicate sunlight\n",
      "年\n",
      "\n",
      "QUESTION: Which is a positive impact on the bio environment?\n",
      "POSSIBLE ANSWERS: A. dumping toxic waste in rivers B. contaminating the ground with poison C. building cars in large numbers D. making sure trash is reused for new reasons\n",
      "====================\n",
      "CONTEXT: Positive impact on the bio environment. Toxic waste is harmful to the environment. Poisoned ground is not good for biological growth. Car fumes destroy the ozone layer. Recycling trash reduces waste on earth. Waste has a negative impact on environment\n",
      "====================\n",
      "FINAL ANSWER: D. making sure trash is reused for new reasons\n",
      "年\n",
      "\n",
      "QUESTION: Digestion is when stomach acid breaks down\n",
      "POSSIBLE ANSWERS: A. a pizza B. a house C. a rock D. a car\n",
      "====================\n",
      "CONTEXT: Digestion is the process of breaking down food. Pizza is food. A house is not food. A rock is not food. A car is not food\n",
      "====================\n",
      "FINAL ANSWER: A. a pizza\n",
      "年\n",
      "\n",
      "QUESTION: If a warm potato is left on a steel sink, the potato will\n",
      "POSSIBLE ANSWERS: A. burn B. lose heat C. get hotter D. warm up\n",
      "====================\n",
      "CONTEXT: Warm potato has a lot of heat energy. Steel sink is a heat conductor. Burning happens when heat is added. Heat conductors remove heat from source\n",
      "====================\n",
      "FINAL ANSWER: B. lose heat\n",
      "年\n",
      "\n",
      "QUESTION: Which is most harmful to a human?\n",
      "POSSIBLE ANSWERS: A. dynamite going off B. reading email C. balloons popping D. opening a soda\n",
      "====================\n",
      "CONTEXT: Things harmful to a human cause physical damage and pain. Dynamite creates high-energy explosions. Emails cannot cause damage to people. Balloons popping are loud but not harmful. Opening a soda releases low levels of energy from compressed gas\n",
      "====================\n",
      "FINAL ANSWER: A. dynamite going off\n",
      "年\n",
      "\n",
      "QUESTION: Water boiling in a pot on a stove is an example of\n",
      "POSSIBLE ANSWERS: A. electrocution B. freezing C. hydroplaning D. thermal conduction\n",
      "====================\n",
      "CONTEXT: Water boiling in a pot on a stove is an example of thermal conduction. Electrocution happens when electricity is added. Freezing happens when heat is removed. Hydroplaning happens when water is added. Thermal conduction happens when heat is added\n",
      "====================\n",
      "FINAL ANSWER: D. thermal conduction\n",
      "年\n",
      "\n",
      "QUESTION: Which is a positive impact on the bio environment?\n",
      "POSSIBLE ANSWERS: A. dumping toxic waste in rivers B. contaminating the ground with\n"
     ]
    }
   ],
   "source": [
    "stopword = \"年\"\n",
    "final_answer_word = \"FINAL ANSWER: \"\n",
    "\n",
    "generated_text = prompt\n",
    "max_iterations = 5\n",
    "for i in range(max_iterations):\n",
    "    temp = generated_text\n",
    "    generated_text = model.query(generated_text)[0]['generated_text']\n",
    "    generated_len = len(generated_text) - len(temp)\n",
    "    if \"stopword\" in generated_text[-generated_len:]: break\n",
    "print(generated_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ewaluacja"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_questions = 20\n",
    "stopword = \"年\"\n",
    "final_answer_prompt = \"FINAL ANSWER: \"\n",
    "\n",
    "questions = [\n",
    "    get_question_dict(train_dict[qid], thoughts)\n",
    "    for qid, thoughts in questions_and_thoughs.items()]\n",
    "answered_question_id_sample = random.sample(list(dev_dict.keys()), n_questions)\n",
    "\n",
    "pcreator = PromptCreator(start_instruction_3, questions, answered_question, question_formatter_2)\n",
    "\n",
    "score_sum = 0\n",
    "for a_id in tqdm(answered_question_id_sample):\n",
    "    answered_question = get_question_dict(dev_dict[a_id], [])\n",
    "    pcreator.set_answered_question(answered_question)\n",
    "    prompt = pcreator.get_full_prompt()\n",
    "\n",
    "    generated_text = generate_text(prompt, 5, stopword)\n",
    "    answer = postprocess_answer(generated_text, stopword, final_answer_prompt)\n",
    "    true_answer = f\"{answered_question['answer']}. {answered_question['answer_text']}\"\n",
    "    score_sum += int(exact_match_score(answer, true_answer))\n",
    "\n",
    "print(f\"Score: {float(score_sum) / n_questions}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}