{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import faiss\n",
    "import json\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [
    {
     "data": {
      "text/plain": "['A bee is a pollinating animal',\n 'A bird is a pollinating animal',\n 'An electrical conductor is a vehicle for the flow of electricity',\n 'An example of a change in the Earth is an ocean becoming a wooded area',\n 'An example of a chemical change is acid breaking down substances']"
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facts_path = \"Data\\Main\\openbook.txt\"\n",
    "with open(facts_path) as f:\n",
    "    facts = [line[1:-2] for line in f.readlines()]\n",
    "facts[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [],
   "source": [
    "model_name = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "embeddings = model.encode(facts)\n",
    "index_flatip = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "index_flatip.add(embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [],
   "source": [
    "# with open(f'index_{model_name}.pickle', 'wb') as f:\n",
    "#     pickle.dump(index, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#\n",
    "# with open(f'index_{model_name}.pickle', 'rb') as f:\n",
    "#     eee = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "data": {
      "text/plain": "['burning a living thing usually causes harm to that living thing',\n 'fire causes burning',\n 'cooking food requires adding heat energy',\n 'if a body part was burned then that body part was exposed to a lot of heat energy',\n 'cooking food to proper temperatures protects against food poisoning by killing bacteria and viruses',\n 'if too much heat is transferred to an object then that object may burn',\n 'if food is cooked then heat energy is added to that food',\n 'burning wood is used to produce heat',\n 'fire causes harm to living things',\n 'cooking causes a chemical reaction']"
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"can you burn yourself with food\"\n",
    "k = 10\n",
    "\n",
    "D, I = index_flatip.search(model.encode([question]), k)\n",
    "result_facts = [facts[i] for i in I[0]]\n",
    "results = list(zip(result_facts, np.round(D[0], 3)))\n",
    "result_facts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [
    "def get_questions_answers(questions_path):\n",
    "    with open(questions_path) as f:\n",
    "        question_sets = [json.loads(line) for line in f.readlines()]\n",
    "    questions = [qset['question']['stem'] for qset in question_sets]\n",
    "    answers = [list(filter(lambda choice: choice['label'] == qset[\"answerKey\"][0], qset['question']['choices']))[0]['text'] for qset in question_sets]\n",
    "    true_facts = [qset['fact1'] for qset in question_sets]\n",
    "    return questions, answers, true_facts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [],
   "source": [
    "questions_path = \"Data\\\\Additional\\\\train_complete.jsonl\"\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "k = 5\n",
    "k_cumulative_metric = 5\n",
    "\n",
    "model_stats = []\n",
    "model_names = [\"all-mpnet-base-v2\", \"multi-qa-mpnet-base-dot-v1\", \"all-distilroberta-v1\", \"all-MiniLM-L12-v2\", \"multi-qa-distilbert-cos-v1\", \"all-MiniLM-L6-v2\", \"multi-qa-MiniLM-L6-cos-v1\", \"paraphrase-multilingual-mpnet-base-v2\", \"paraphrase-albert-small-v2\", \"paraphrase-multilingual-MiniLM-L12-v2\", \"paraphrase-MiniLM-L3-v2\", \"distiluse-base-multilingual-cased-v1\", \"distiluse-base-multilingual-cased-v2\"]\n",
    "\n",
    "questions, answers, true_facts = get_questions_answers(questions_path)\n",
    "# question_indexes = random.sample(range(len(questions)), n_questions)\n",
    "question_indexes = range(len(questions))\n",
    "n_questions = len(questions)\n",
    "\n",
    "for model_name in model_names:\n",
    "\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    embeddings = model.encode(facts)\n",
    "    faissindex = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "    faissindex.add(embeddings)\n",
    "\n",
    "    model_scores = []\n",
    "    model_hits = []\n",
    "    for i in question_indexes:\n",
    "        question, answer, true_fact = questions[i], answers[i], true_facts[i]\n",
    "\n",
    "        D, I = faissindex.search(model.encode([question]), k)\n",
    "        result_facts = [facts[i] for i in I[0]]\n",
    "        results = list(zip(result_facts, np.round(D[0], 3)))\n",
    "\n",
    "        score = 0\n",
    "        for result_fact in result_facts[:k_cumulative_metric]:\n",
    "            trsfm = tfidf_vect.fit_transform([answer, result_fact])\n",
    "            score += cosine_similarity(trsfm[0:1], trsfm)[0][1]\n",
    "        model_scores.append(score)\n",
    "\n",
    "        hit = 1 if true_fact in result_facts else 0\n",
    "        model_hits.append(hit)\n",
    "\n",
    "    model_stats.append({\n",
    "        \"model_name\": model_name,\n",
    "        \"cosine_scores\": model_scores,\n",
    "        \"fact_hits\": model_hits\n",
    "    })"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0931 0.6637078878353843 all-mpnet-base-v2\n",
      "0.0877 0.6544280815009078 multi-qa-mpnet-base-dot-v1\n",
      "0.0915 0.6280008069396813 all-distilroberta-v1\n",
      "0.0894 0.6324389751866047 all-MiniLM-L12-v2\n",
      "0.0882 0.635061529150696 multi-qa-distilbert-cos-v1\n",
      "0.0882 0.6263869275771636 all-MiniLM-L6-v2\n",
      "0.0847 0.6082307847488401 multi-qa-MiniLM-L6-cos-v1\n",
      "0.0846 0.609642929191043 paraphrase-multilingual-mpnet-base-v2\n",
      "0.0715 0.5386322372402663 paraphrase-albert-small-v2\n",
      "0.0762 0.5499293927778899 paraphrase-multilingual-MiniLM-L12-v2\n",
      "0.0624 0.5259229372604398 paraphrase-MiniLM-L3-v2\n",
      "0.0821 0.529150695985475 distiluse-base-multilingual-cased-v1\n",
      "0.0818 0.5396409118418398 distiluse-base-multilingual-cased-v2\n"
     ]
    }
   ],
   "source": [
    "for stat in model_stats:\n",
    "    print(round(np.mean(stat[\"cosine_scores\"]), 4), np.sum(stat[\"fact_hits\"])/n_questions, stat[\"model_name\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}